# 如何理解AI for Science?

## 1、AI技术的发展与应用领域

​      **人工智能（Artificial Intelligence，AI）**近年来无疑是科学界的热点话题。信息科学以及人工智能技术不仅加快社会生活的步伐，也在**推动传统行业的加速革新**，如**人脸识别、生物识别、工业检测、推荐系统、具身智能**等。

<img src="E:\大学课件\大三下\地球物理测井\测井汇报\图片\人工智能.drawio (1).png" alt="人工智能.drawio (1)" style="zoom: 67%;" />

​       目前AI界深度学习主流的研究方向主要有，**计算机视觉（Computer Vision，CV）**和**自然语言处理（Natural Language Processing,NLP）**,当然还有**融合视觉与文本甚至语音研究的多模态（Mutimodality）方向**，则是致力于把视觉与文本甚至语音大一统起来。



### 1.1 CV（Computer Vision）

​         计算机视觉领域研究视觉相关的问题，**如图像、视频的识别、分类、理解以及基于图像、视频的应用**。计算机视觉在近十几年来也经历了快速发展的时期，从最初的**手写数字体（MNIST）识别**到**ImageNet数据集的识别**再到后面CoCo数据集等等各种丰富的数据集。起初视觉领域做的都是**有监督的分类**，即图片带了标签或类别信息，通过训练模型学习图像特征使得**模型能够预测出图片类别**，模型也**从LeNet到AlexNet、ResNet、Google-Net、VGG-Net等**（上述均为卷积神经网络）在**ImageNet数据集**上识别的准确率不断提升，而模型的规模也在不断变大，**后续也出现了大量无监督或者自监督的模型**。在近十年的发展过程中，视觉领域的数据集以及模型和算法越发丰富了（常用数据集如表1-1所示）。视觉领域的任务同样广泛，**如物体检测、语义分割、实例分割、目标识别、目标计数、视频理解、姿势检测等**，在科研与工业应用上都具有及其重要的研究意义。

<center>表1-1 视觉领域经典数据集

| 数据集     | 创建时间     | 描述                                                         |
| ---------- | ------------ | ------------------------------------------------------------ |
| MNIST      | 1999         | **入门级数据集，手写数字图片数据集，包括60000张图片训练集与10000张测试集图片组成**，每张图片为**28*28的0至255的灰度值组成**，手写数字体识别 |
| FMINIST    | 2017         | 手写数字数据集变种，**包含60,000个训练图像和10,000个测试图像，数据集分为10个类别**，包括**T恤/上衣、裤子、套头衫、连衣裙、外套、凉鞋、衬衫、运动鞋、包和靴子**。 |
| ImageNet   | 2009         | 斯坦福大学李飞飞牵头创建，**ImageNet包含超过1400万张图像，涵盖超过2万个类别。ImageNet-1K为1000类，每类约1000张图片，约100万张图片数据集。** |
| COCO       | 2014         | **COCO（Common Objects in Context）**数据集主要用于**目标检测、分割、字幕生成、人体关键点检测等计算机视觉任务**。COCO数据集包含**超过33万张图像，超过200万个对象实例**，涵盖**80个类别**。这些类别包括常见的物体（如人、动物、车辆）、家具、工具等。 |
| LabelMe    | 2000左右     | LabelMe数据集**包含大量的图像，每张图像都附有详细的注释信息**，包括对象的**边界框、分割掩码、类别标签等**。它也是一个**重要的图像标注工具**。 |
| Kinetics   | 2017         | Kinetics数据集是一个用于**视频动作识别的大型数据集**，截至当前版本，Kinetics数据集已包含超过**65万个视频样本**，当然后续数据集可能越来越大。**分为700多个动作类别**，**每个类别包含至少400个不同的视频实例，每个视频片段的时长大约为10秒。** |
| Pascal VOC | 2005         | Pascal VOC（Visual Object Classes）是一个在计算机视觉领域中广泛使用的数据集，主要用于**评估和促进对象识别、分类、目标检测、图像分割以及其他视觉理解任务的算法性能**。数据规模适中，包含多个类别的多张图片。 |
| CelebA     | 2015         | **CelebA（CelebFaces Attributes Dataset）**是一个**广泛用于人脸识别和人脸属性分析的大规模人脸数据集**。包含**来自10,177名名人的超过202,599张面部图片及其属性标签**。可用于人脸识别、人脸属性分析、人脸生成。 |
| OpenImages | 2024 v7      | **包含900多万张图片，涵盖600个类别OpenImages数据集包含数百万张有标记的图像**，是现有最大的**物体位置注释数据集之一**。**提供边界框、对象分割、视觉关系、本地化叙述和点级标签等多种标注**，标注精度较高。 |
| WIDER FACE | 2018         | WIDER FACE是一个用于人脸检测任务的大规模数据集，由香港中文大学的研究人员于2018年发布。  **图像数量：32,203张 ；人脸标注数量：393,703个** |
| CIFAR-10   | 1990         | 图像分类基准数据集。**图像数量：共60,000张  训练集：50,000张 测试集：10,000张。**  图像尺寸：每张图像为**32x32像素的彩色图像** 图像格式：RGB三通道彩色图像，每个像素点包含RGB三个数值，数值范围为0~255 类别数量：**10个类别，包括飞机（Airplane）、汽车（Automobile）、鸟类（Bird）、猫（Cat）、鹿（Deer）、狗（Dog）、蛙（Frog）、马（Horse）、船（Ship）和卡车（Truck）**。后续对应有CIFAR-100 |
| LSUN       | 2010年代中后 | **LSUN（Large-scale Scene UNderstanding）是一个用于场景理解任务的大规模数据集**，由斯坦福大学的研究团队创建。  类别数量：**10个场景类别，如卧室、厨房、客厅、教堂、餐厅等**。 图像数量：**每个场景类别包含大约100万张标记图像**，但具体数量可能因类别而异，范围从大约120,000到3,000,000张不等。 |
| ...        | ...          | ...                                                          |

​	需要得到泛化性能优越的模型，**大规模与高质量的数据必不可缺**。经过多年的发展，视觉领域的数据集也相当丰富，如**LabelMe、CoCo、Pascal VOC**具体如上表列举了常用数据集，当然不同领域或不同下游任务的数据集就更加丰富了（kaggle上汇集了大量开源数据集及相关竞赛）。

​        我们不得不承认的是，**现实世界的图像数据是海量的，海量图像具有各种场景、语义、物体等**，对现实世界的所有图像训练出一个大而强的视觉模型无疑是困难重重。**但是我们可以从特定几个场景入手，目前针对某些特定场景的数据集训练出的模型，在其下游任务上仍具有重要意义。**表2-2列出了主要视觉领域的下游任务，主要为。

<center>表1-2视觉领域主要的下游任务
</center>

| 序号 | 任务             | 说明                                                         |
| ---- | ---------------- | :----------------------------------------------------------- |
| 1    | 图像分类         | 图像分类是计算机视觉中**最基础的任务之一**，其目标是**根据图像的语义信息将不同类别的图像进行区分**。 应用场景广泛，包括安防领域的人脸识别和智能视频分析、交通领域的**交通场景识别**、互联网领域基于内容的图像检索和**相册自动归类，以及医学领域的图像识别**等。 |
| 2    | 目标检测         | 目标检测任务的目标是给定一张图像或是一个视频帧，让计算机**找出其中所有目标的位置**，并给出每个**目标的具体类别**。常用的模型包括**SSD（Single Shot MultiBox Detector）**、**PyramidBox（百度自主研发的人脸检测模型）**以及**R-CNN系列**模型（如Faster R-CNN和Mask R-CNN）和**YoLo系列**等。 |
| 3    | 语义分割         | 图像语义分割是指**将图像像素按照表达的语义含义的不同进行分组/分割**。常用的模型包括**DeepLab系列**（如DeepLab v3+），这些模型**通过encoder-decoder结构进行多尺度信息的融合**，以实现高精度的语义分割。 |
| 4    | 场景文字识别     | 场景文字识别是指**从自然场景图像中识别出文字信息**。 **这在自动驾驶、智能监控、机器人导航**等领域具有重要应用价值。 |
| 5    | 图像生成         | 图像生成任务包括从文本生成图像、从噪声生成图像等。 这类任务通常利用**生成对抗网络（GAN）**等深度学习模型来实现。 生成的图像可以用于**艺术创作、虚拟试妆、游戏开发**等多个领域。 |
| 6    | 人体关键点检测   | 人体关键点检测是指**从图像或视频中识别人体的关键部位（如头部、四肢等）并定位其位置**。 这在**动作识别、姿态估计、人机交互**等领域具有重要应用价值。 |
| 7    | 视频分类（理解） | 视频分类任务与图像分类类似，但**处理的对象是图像序列**。 它需要**对视频中的每一帧或关键帧进行分类，以识别出视频的整体内容或主题**。 |
| 8    | 度量学习         | 度量学习是一种**学习样本间相似性或距离度量的方法**。 在计算机视觉中，度量学习可以用于人脸识别、图像检索等任务中，以提高模型的识别精度和检索效率。 |

​         经典的视觉框架模型有**CNN、CNN变种（ResNet、Google-Net、VGG-Net）、GAN、MoCo、Vision Transformer、Swin Transformer等**。

<center> 表1-3视觉领域常用的框架模型
</center>

| 模型框架         | 时间      | 框架                                                         |
| ---------------- | --------- | ------------------------------------------------------------ |
| LeNet            | 1998      | LeNet5 一共**由7 层组成**，分别是**C1、C3、C5 卷积层，S2、S4 降采样层（降采样层又称池化层），F6 为一个全连接层**，输出是一个高斯连接层，**该层使用softmax 函数对输出图像进行分类**。模型主要针对MNIST识别。 |
| AlexNet          | 2012      | AlexNet中包含了几个比较新的技术点，包括首次**在CNN中成功应用了ReLU、Dropout和LRN等技巧**。同时AlexNet也使用了**并行的GPU进行运算加速**。 |
| VGG-Net          | 2014      | VGGNet是牛津大学**视觉几何组（Visual Geometry Group)**提出的模型，故简称VGGNet，该模型证明了增加网络的**深度**能够在一定程度上影响网络最终的性能。 |
| Google-Net       | 2014      | **inception的提出**则从另一种角度来提升训练结果：**能更高效的利用计算资源，在相同的计算量下能提取到更多的特征，从而提升训练结果**。 |
| ResNet           | 2015      | ResNet网络是在2015年由微软实验室中的何凯明等几位大神提出，在ImageNet的分类比赛上将网络**深度**直接提高到了**152层**，前一年夺冠的VGG只有19层。除了深度加深这一点外，还提出**residual（残差结构）模块**。另外使用**Batch Normalization**加速训练（丢弃dropout）。 |
| GAN              | 2014      | **Goodfellow 等人启发自博弈论中的二人零和博弈，开创性地提出了生成对抗网络 （GAN）**。生成对抗网络包含一**个生成模型和一个判别模型**。其中，**生成模型负责捕捉样本数据的分布，而判别模型一般情况下是一个二分类器，判别输入是真实数据还是生成的样本**。GAN还有诸多变体，常用于图像生成任务，如样式迁移。 |
| VIT              | 2019      | **将Transformer用于视觉领域，图像输入用可以分成多个patch**，同文本一样进行嵌入与编码，用于预训练。再次展现Transformer的强大性能。 |
| MoCo             | 2020      | **MoCo（Momentum Contrast）是一种用于自监督学习和无监督表示学习的深度学习方法**，尤。它旨在**通过对比学习（Contrastive Learning）**的方式，从未标记的数据中学习有用的特征表示。MoCo 方法的核心思想是利用一个**动量更新的编码器（Momentum Encoder）**来构建一个**大型且一致的特征字典（Key Memory Bank）**，以便与当前的小批量（Mini-Batch）数据进行对比学习。 |
| Swin-Transformer | 2021      | 是一种**解决视觉图像多尺度问题的层级式网络结构**，其特点在于使用**移位窗口（Shifted Windows）来降低计算复杂度**，并适用于分类、分割和目标检测等多种视觉任务。 |
| BeiT             | 2021      | BeiT模型是一种创新的图像预训练模型，它结合了BERT（Bidirectional Encoder Representations from Transformers）的架构和dVAE（discrete Variance Auto-Encoder，离散变分自编码器）的思想，旨在通过掩码图像建模（Masked Image Modeling, MIM）的方式实现图像的预训练。 |
| .   .   .        | .   .   . | .   .   .                                                    |



### 1.2 NLP（Natural Language Processing）

自然语言处理则研究**文本语言形式的信息**，主流的框架模型有**RNN、LSTM、GRU、ElMo、Transformer、BERT等**，主要的任务有机器翻译、语言理解、文本生成等任务。

​        **与视觉领域相似，要训练强的语言模型，文本数据集是原料**。文本领域的数据集同样丰富，**有机器阅读理解、问答系统、文本分类、对话系统、大规模语料库及特定领域数据集等**。表1-4陈列了文本领域的相关数据集。

<center>表1-4 文本领域的数据集
</center>

| 序号 | 数据集                                                       | 分类描述           |
| ---- | ------------------------------------------------------------ | ------------------ |
| 1    | **SQuAD（Stanford Question Answering Dataset）**：源自维基百科文章的问答对集合，任务是找出文本中答案所在的跨度。 | 机器阅读理解数据集 |
| 2    | **Chinese Squad**：中文机器阅读理解数据集，通过机器翻译加人工校正的方式从原始SQuAD转换而来。 | 机器阅读理解数据集 |
| 3    | **CMRC 2018**：包含第二届“讯飞杯”中文机器阅读理解评测所使用的数据。 | 机器阅读理解数据集 |
| 4    | **Delta 阅读理解数据集（DRCD）**：通用领域繁体中文机器阅读理解资料集，包含来自维基百科文章的段落和问题。 | 机器阅读理解数据集 |
| 5    | **Zero-SCROLLS**：包含十个自然语言任务的测试集，其中包括Qasper、NarrativeQA等问题解答数据集。 | 问答系统数据集     |
| 6    | **L-Eval**：从规模较小的类似公共数据集中重新标注数据和指令，涵盖法律、金融、学术论文等多个领域，包含多种题型如选择题、真假题、数学题、代码理解等。 | 问答系统数据集     |
| 7    | **Amazon Reviews Dataset**：包含数百万条亚马逊客户评论和星级评定，用于情感分析。 | 文本分类数据集     |
| 8    | **IMDB数据集**：包含5万条影评，用于二进制情绪分类。          | 文本分类数据集     |
| 9    | **Yelp Reviews Dataset**：包含来自多个大都市区的餐厅评论，可用于命名实体识别、情感分析等任务。 | 文本分类数据集     |
| 10   | **CrossWOZ**：中文任务导向对话数据集，包含5个场景的6k个对话和102k个句子。 | 对话数据集         |
| 11   | **MedDialog**：大规模的医疗对话数据集，包含医生和患者之间的对话。 | 对话数据集         |
| 12   | **Ape210K**：中文数据集，包含210k个中国小学水平的数学问题，每个问题都包含最佳答案和得出答案所需的方程式。 | 特定领域数据集     |
| 13   | **Math23K**：为解决数学单词问题而创建的数据集，包含从互联网上爬取的23,162个中文问题。 | 特定领域数据集     |
| 14   | **Belle**：包含约350万条由BELLE项目生成的中文指令数据，用于评估各种模型。 | 指令数据集         |
| 15   | **中文互联网语料库CCI (Chinese Corpora Internet) 2.0**：由北京智源人工智能研究院发布，包含超过500G的中文文本数据，既包括智源研究院大模型“悟道”的数据集，也包括全国20多家互联网和其他企业的数据贡献。 | 大规模语料库       |

从上表中所列的数据集不难看出，**文本领域的下游任务**应该包括**文本理解、语言机器翻译、文本分类、文本生成（对话系统、问答系统）等。**

主流的模型框架：

<center>表1-5 文本领域相关的模型框架

| 序号 | 模型        | 描述                                                         |
| ---- | ----------- | ------------------------------------------------------------ |
| 1    | RNN         | RNN(Recurrent Neaural network,循环神经网络)，常用于序列建模，如时间序列和深度序列等。对于可序列化的场景，可用RNN捕捉序列间的关系，基于序列的预测。LSTM和GRU为RNN的变体。 |
| 2    | LSTM        | LSTM（Long and Short Term Memory Neural Network,长短期记忆网络）,为RNN变体。网络对于每一个时间步，能够学习之前时间步的隐藏层和当前时间步的输入的信息，通过sigmoid函数以及tanh函数等非线性函数对序列信息建模（非线性函数具有良好的过滤功能），得到当前时间步的输出。 |
| 3    | GRU         | GRU（Gated Recurrent Unit Neaural Network,门控循环单元神经网络）,RNN变体，借助数电或者说控制论的思想，对每个时间步设置门电路，分别有重置门（Reset Gate）、遗忘门（Forget Gate）、更新门（Updated Gate），各个门分别使用不同的函数实现对应的逻辑功能，实现序列化建模。 |
| 4    | ElMo        | ElMo（）                                                     |
| 5    | Transformer | 基于注意力（attention）机制的基础架构，对于文本（序列）信息，运用注意力机制捕捉全局文本的相关性。架构总体有两端，一是编码端（encoder），另外一端是解码端（decoder）。attention机制显示出对序列信息具有强大的学习能力，后续文本及图像领域的大模型也都采用了transformer这种基本架构。 |
| 6    | BERT        | BERT（Bidirectional Enoder Representation Transformer）。    |
| 7    | . . .       | . . .                                                        |



### 1.3 mutimodality

多模态方向则是**融合视觉与文本**，针对跨模态涉及模型进行学习。

<center>表 1-5 多模态对应的模型框架
</center>

| 序号 | 模型 |      |
| ---- | ---- | ---- |
| 1    |      |      |
| 2    |      |      |
| 3    |      |      |



## 2、AI for Biology

## 3、AI for Material

## 4、AI for Ecology

## 5、AI for Medicine

## 6、AI for Geology

## 7、AI for Others

